#!/usr/bin/env python3
"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
è®­ç»ƒä»·æ ¼é¢„æµ‹æ¨¡å‹
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            ),
            'gradient_boosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
        }
        self.best_model = None
        self.best_score = 0
    
    def prepare_data(self, df: pd.DataFrame) -> tuple:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        
        # ç‰¹å¾åˆ— (æ’é™¤éç‰¹å¾åˆ—)
        feature_cols = [col for col in df.columns if col not in 
                       ['timestamp', 'target', 'price']]
        
        X = df[feature_cols]
        y = df['target']
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        return X_train, X_test, y_train, y_test, feature_cols
    
    def train_models(self, X_train, y_train):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹")
        
        for name, model in self.models.items():
            print(f"\nğŸ“Š è®­ç»ƒ {name}...")
            
            # è®­ç»ƒ
            model.fit(X_train, y_train)
            
            # äº¤å‰éªŒè¯
            scores = cross_val_score(model, X_train, y_train, cv=5)
            mean_score = scores.mean()
            
            print(f"   äº¤å‰éªŒè¯å‡†ç¡®ç‡: {mean_score:.3f} (+/- {scores.std()*2:.3f})")
            
            # é€‰æ‹©æœ€ä½³æ¨¡å‹
            if mean_score > self.best_score:
                self.best_score = mean_score
                self.best_model = model
                print(f"   â­ å½“å‰æœ€ä½³æ¨¡å‹: {name}")
    
    def evaluate_model(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        
        if self.best_model is None:
            print("âŒ æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
        
        # é¢„æµ‹
        y_pred = self.best_model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, average='weighted'),
            'recall': recall_score(y_test, y_pred, average='weighted'),
            'f1': f1_score(y_test, y_pred, average='weighted')
        }
        
        print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {metrics['accuracy']:.3f}")
        print(f"   ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
        print(f"   å¬å›ç‡: {metrics['recall']:.3f}")
        print(f"   F1åˆ†æ•°: {metrics['f1']:.3f}")
        
        return metrics
    
    def get_feature_importance(self, feature_names: list) -> pd.DataFrame:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        
        if self.best_model is None:
            return None
        
        importance = self.best_model.feature_importances_
        
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        print("\nğŸ” ç‰¹å¾é‡è¦æ€§ (Top 10):")
        print(importance_df.head(10).to_string(index=False))
        
        return importance_df
    
    def save_model(self, filepath: str = 'models/prediction_model.pkl'):
        """ä¿å­˜æ¨¡å‹"""
        
        if self.best_model is None:
            print("âŒ æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
        
        import os
        os.makedirs('models', exist_ok=True)
        
        joblib.dump(self.best_model, filepath)
        print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath: str = 'models/prediction_model.pkl'):
        """åŠ è½½æ¨¡å‹"""
        
        self.best_model = joblib.load(filepath)
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {filepath}")

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    from feature_engineering import FeatureEngineer
    import json
    
    # åŠ è½½æ•°æ®
    with open('historical_data/sample_history.json', 'r') as f:
        data = json.load(f)
    
    # ç‰¹å¾å·¥ç¨‹
    engineer = FeatureEngineer()
    df = engineer.process_all_features(data)
    
    # è®­ç»ƒæ¨¡å‹
    trainer = ModelTrainer()
    X_train, X_test, y_train, y_test, feature_cols = trainer.prepare_data(df)
    trainer.train_models(X_train, y_train)
    trainer.evaluate_model(X_test, y_test)
    trainer.get_feature_importance(feature_cols)
    trainer.save_model()
