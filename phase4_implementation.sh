#!/bin/bash
# Phase 4 å®æ–½è„šæœ¬ - æœºå™¨å­¦ä¹ ä¼˜åŒ–
# è¿è¡Œ: bash phase4_implementation.sh

echo "=========================================="
echo "ğŸ§  Phase 4 å®æ–½: æœºå™¨å­¦ä¹ ä¼˜åŒ–"
echo "=========================================="
echo ""

echo "ğŸ“‹ æœºå™¨å­¦ä¹ æ¶æ„"
echo "------------------------------"
echo ""
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "â”‚        æœºå™¨å­¦ä¹ äº¤æ˜“ç³»ç»Ÿ v1.0            â”‚"
echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
echo "â”‚                                         â”‚"
echo "â”‚  å†å²æ•°æ®  â†’  ç‰¹å¾å·¥ç¨‹  â†’  æ¨¡å‹è®­ç»ƒ     â”‚"
echo "â”‚     â†‘              â†“           â†“       â”‚"
echo "â”‚  å›æµ‹éªŒè¯  â†  ä¿¡å·ç”Ÿæˆ  â†  é¢„æµ‹æ¨¡å‹     â”‚"
echo "â”‚                                         â”‚"
echo "â”‚  è‡ªåŠ¨ä¼˜åŒ–  â†’  å‚æ•°è°ƒä¼˜  â†’  éƒ¨ç½²ä¸Šçº¿     â”‚"
echo "â”‚                                         â”‚"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
echo ""

# åˆ›å»ºå†å²æ•°æ®æ”¶é›†æ¨¡å—
echo "ğŸ“‹ æ­¥éª¤ 1: åˆ›å»ºå†å²æ•°æ®æ”¶é›†ç³»ç»Ÿ"
echo "------------------------------"

cat > historical_data_collector.py << 'EOF'
#!/usr/bin/env python3
"""
å†å²æ•°æ®æ”¶é›†å™¨
æ”¶é›† Polymarket å†å²æ•°æ®ç”¨äºå›æµ‹
"""

import os
import json
import asyncio
import aiohttp
from datetime import datetime, timedelta
from pathlib import Path

class HistoricalDataCollector:
    """å†å²æ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self):
        self.data_dir = Path("historical_data")
        self.data_dir.mkdir(exist_ok=True)
        
        # è¦æ”¶é›†çš„å¸‚åœº
        self.markets = [
            "Will Donald Trump win the 2024 U.S. presidential election?",
            "Will Joe Biden win the 2024 U.S. presidential election?",
            "Will Bitcoin ETF be approved by January 2024?",
            # æ·»åŠ æ›´å¤šå¸‚åœº...
        ]
    
    async def fetch_market_history(self, market_id: str, days: int = 90) -> list:
        """è·å–å¸‚åœºå†å²ä»·æ ¼æ•°æ®"""
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨ Polymarket API è·å–å†å²æ•°æ®
        # ç®€åŒ–ç‰ˆç¤ºä¾‹
        
        history = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # æ¨¡æ‹Ÿæ•°æ® (å®é™…åº”è¯¥ä» API è·å–)
        current_date = start_date
        while current_date <= end_date:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™… API
            history.append({
                'timestamp': current_date.isoformat(),
                'price': 0.5,  # æ¨¡æ‹Ÿä»·æ ¼
                'volume': 1000,
                'liquidity': 50000
            })
            current_date += timedelta(hours=1)
        
        return history
    
    async def collect_all_data(self):
        """æ”¶é›†æ‰€æœ‰æ•°æ®"""
        print("ğŸš€ å¼€å§‹æ”¶é›†å†å²æ•°æ®")
        
        for market in self.markets:
            print(f"\nğŸ“Š æ”¶é›†: {market[:50]}...")
            
            history = await self.fetch_market_history(market)
            
            # ä¿å­˜æ•°æ®
            filename = self.data_dir / f"{market.replace(' ', '_')[:30]}_history.json"
            with open(filename, 'w') as f:
                json.dump(history, f, indent=2)
            
            print(f"   âœ… å·²ä¿å­˜ {len(history)} æ¡è®°å½•")
        
        print("\nâœ… æ•°æ®æ”¶é›†å®Œæˆ")

if __name__ == "__main__":
    collector = HistoricalDataCollector()
    asyncio.run(collector.collect_all_data())
EOF

echo "âœ… å†å²æ•°æ®æ”¶é›†å™¨å·²åˆ›å»º"
echo ""

# åˆ›å»ºç‰¹å¾å·¥ç¨‹æ¨¡å—
echo "ğŸ“‹ æ­¥éª¤ 2: åˆ›å»ºç‰¹å¾å·¥ç¨‹æ¨¡å—"
echo "------------------------------"

cat > feature_engineering.py << 'EOF'
#!/usr/bin/env python3
"""
ç‰¹å¾å·¥ç¨‹æ¨¡å—
ä»åŸå§‹æ•°æ®ä¸­æå–æœ‰æ„ä¹‰çš„ç‰¹å¾
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import List, Dict

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.features = []
    
    def extract_price_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æå–ä»·æ ¼ç›¸å…³ç‰¹å¾"""
        
        # ä»·æ ¼åŠ¨é‡
        df['price_momentum_1h'] = df['price'].pct_change(periods=1)
        df['price_momentum_24h'] = df['price'].pct_change(periods=24)
        df['price_momentum_7d'] = df['price'].pct_change(periods=168)
        
        # æ³¢åŠ¨ç‡
        df['volatility_1h'] = df['price'].rolling(window=24).std()
        df['volatility_24h'] = df['price'].rolling(window=168).std()
        
        # ç§»åŠ¨å¹³å‡çº¿
        df['ma_1h'] = df['price'].rolling(window=24).mean()
        df['ma_24h'] = df['price'].rolling(window=168).mean()
        
        # RSI
        delta = df['price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        return df
    
    def extract_volume_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æå–äº¤æ˜“é‡ç‰¹å¾"""
        
        # äº¤æ˜“é‡å˜åŒ–
        df['volume_change_1h'] = df['volume'].pct_change(periods=1)
        df['volume_change_24h'] = df['volume'].pct_change(periods=24)
        
        # äº¤æ˜“é‡ç§»åŠ¨å¹³å‡
        df['volume_ma_1h'] = df['volume'].rolling(window=24).mean()
        df['volume_ma_24h'] = df['volume'].rolling(window=168).mean()
        
        # é‡ä»·å…³ç³»
        df['volume_price_ratio'] = df['volume'] / df['price']
        
        return df
    
    def extract_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æå–æ—¶é—´ç‰¹å¾"""
        
        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
        df['day_of_week'] = pd.to_datetime(df['timestamp']).dt.dayofweek
        df['day_of_month'] = pd.to_datetime(df['timestamp']).dt.day
        
        # æ˜¯å¦å‘¨æœ«
        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
        
        return df
    
    def extract_sentiment_features(self, df: pd.DataFrame, sentiment_data: Dict) -> pd.DataFrame:
        """æå–æƒ…ç»ªç‰¹å¾"""
        
        # Twitter æƒ…ç»ª
        df['twitter_sentiment'] = sentiment_data.get('twitter', 0.5)
        
        # æ°‘è°ƒåå·®
        df['poll_divergence'] = sentiment_data.get('poll_divergence', 0)
        
        # æ–°é—»æƒ…ç»ª
        df['news_sentiment'] = sentiment_data.get('news', 0.5)
        
        return df
    
    def create_target_variable(self, df: pd.DataFrame, lookahead: int = 24) -> pd.DataFrame:
        """åˆ›å»ºç›®æ ‡å˜é‡ (æœªæ¥ä»·æ ¼æ–¹å‘)"""
        
        # æœªæ¥24å°æ—¶çš„ä»·æ ¼å˜åŒ–
        future_return = df['price'].shift(-lookahead) / df['price'] - 1
        
        # åˆ†ç±»ç›®æ ‡: 1 (ä¸Šæ¶¨), 0 (æŒå¹³), -1 (ä¸‹è·Œ)
        df['target'] = np.where(future_return > 0.02, 1,
                               np.where(future_return < -0.02, -1, 0))
        
        return df
    
    def process_all_features(self, data: List[Dict], sentiment_data: Dict = None) -> pd.DataFrame:
        """å¤„ç†æ‰€æœ‰ç‰¹å¾"""
        
        df = pd.DataFrame(data)
        
        # æå–å„ç±»ç‰¹å¾
        df = self.extract_price_features(df)
        df = self.extract_volume_features(df)
        df = self.extract_time_features(df)
        
        if sentiment_data:
            df = self.extract_sentiment_features(df, sentiment_data)
        
        df = self.create_target_variable(df)
        
        # åˆ é™¤ NaN å€¼
        df = df.dropna()
        
        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(df)} æ ·æœ¬, {len(df.columns)} ç‰¹å¾")
        
        return df

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    import json
    
    # åŠ è½½å†å²æ•°æ®
    with open('historical_data/sample_history.json', 'r') as f:
        data = json.load(f)
    
    engineer = FeatureEngineer()
    features_df = engineer.process_all_features(data)
    
    print("\nç‰¹å¾åˆ—è¡¨:")
    print(features_df.columns.tolist())
    print("\nå‰5è¡Œ:")
    print(features_df.head())
EOF

echo "âœ… ç‰¹å¾å·¥ç¨‹æ¨¡å—å·²åˆ›å»º"
echo ""

# åˆ›å»ºæ¨¡å‹è®­ç»ƒæ¨¡å—
echo "ğŸ“‹ æ­¥éª¤ 3: åˆ›å»ºæ¨¡å‹è®­ç»ƒæ¨¡å—"
echo "------------------------------"

cat > model_training.py << 'EOF'
#!/usr/bin/env python3
"""
æ¨¡å‹è®­ç»ƒæ¨¡å—
è®­ç»ƒä»·æ ¼é¢„æµ‹æ¨¡å‹
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import joblib

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            ),
            'gradient_boosting': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
        }
        self.best_model = None
        self.best_score = 0
    
    def prepare_data(self, df: pd.DataFrame) -> tuple:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        
        # ç‰¹å¾åˆ— (æ’é™¤éç‰¹å¾åˆ—)
        feature_cols = [col for col in df.columns if col not in 
                       ['timestamp', 'target', 'price']]
        
        X = df[feature_cols]
        y = df['target']
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        return X_train, X_test, y_train, y_test, feature_cols
    
    def train_models(self, X_train, y_train):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹")
        
        for name, model in self.models.items():
            print(f"\nğŸ“Š è®­ç»ƒ {name}...")
            
            # è®­ç»ƒ
            model.fit(X_train, y_train)
            
            # äº¤å‰éªŒè¯
            scores = cross_val_score(model, X_train, y_train, cv=5)
            mean_score = scores.mean()
            
            print(f"   äº¤å‰éªŒè¯å‡†ç¡®ç‡: {mean_score:.3f} (+/- {scores.std()*2:.3f})")
            
            # é€‰æ‹©æœ€ä½³æ¨¡å‹
            if mean_score > self.best_score:
                self.best_score = mean_score
                self.best_model = model
                print(f"   â­ å½“å‰æœ€ä½³æ¨¡å‹: {name}")
    
    def evaluate_model(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        
        if self.best_model is None:
            print("âŒ æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
        
        # é¢„æµ‹
        y_pred = self.best_model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, average='weighted'),
            'recall': recall_score(y_test, y_pred, average='weighted'),
            'f1': f1_score(y_test, y_pred, average='weighted')
        }
        
        print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {metrics['accuracy']:.3f}")
        print(f"   ç²¾ç¡®ç‡: {metrics['precision']:.3f}")
        print(f"   å¬å›ç‡: {metrics['recall']:.3f}")
        print(f"   F1åˆ†æ•°: {metrics['f1']:.3f}")
        
        return metrics
    
    def get_feature_importance(self, feature_names: list) -> pd.DataFrame:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        
        if self.best_model is None:
            return None
        
        importance = self.best_model.feature_importances_
        
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        print("\nğŸ” ç‰¹å¾é‡è¦æ€§ (Top 10):")
        print(importance_df.head(10).to_string(index=False))
        
        return importance_df
    
    def save_model(self, filepath: str = 'models/prediction_model.pkl'):
        """ä¿å­˜æ¨¡å‹"""
        
        if self.best_model is None:
            print("âŒ æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
        
        import os
        os.makedirs('models', exist_ok=True)
        
        joblib.dump(self.best_model, filepath)
        print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath: str = 'models/prediction_model.pkl'):
        """åŠ è½½æ¨¡å‹"""
        
        self.best_model = joblib.load(filepath)
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {filepath}")

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    from feature_engineering import FeatureEngineer
    import json
    
    # åŠ è½½æ•°æ®
    with open('historical_data/sample_history.json', 'r') as f:
        data = json.load(f)
    
    # ç‰¹å¾å·¥ç¨‹
    engineer = FeatureEngineer()
    df = engineer.process_all_features(data)
    
    # è®­ç»ƒæ¨¡å‹
    trainer = ModelTrainer()
    X_train, X_test, y_train, y_test, feature_cols = trainer.prepare_data(df)
    trainer.train_models(X_train, y_train)
    trainer.evaluate_model(X_test, y_test)
    trainer.get_feature_importance(feature_cols)
    trainer.save_model()
EOF

echo "âœ… æ¨¡å‹è®­ç»ƒæ¨¡å—å·²åˆ›å»º"
echo ""

# åˆ›å»ºè‡ªåŠ¨ä¼˜åŒ–æ¨¡å—
echo "ğŸ“‹ æ­¥éª¤ 4: åˆ›å»ºè‡ªåŠ¨ä¼˜åŒ–æ¨¡å—"
echo "------------------------------"

cat > auto_optimizer.py << 'EOF'
#!/usr/bin/env python3
"""
è‡ªåŠ¨ä¼˜åŒ–æ¨¡å—
ä½¿ç”¨ Optuna è‡ªåŠ¨ä¼˜åŒ–ç­–ç•¥å‚æ•°
"""

import optuna
from datetime import datetime
import json

def optimize_strategy_params():
    """
    ä¼˜åŒ–ç­–ç•¥å‚æ•°
    
    ç›®æ ‡: æœ€å¤§åŒ–æ”¶ç›Š / æœ€å°åŒ–å›æ’¤
    """
    
    def objective(trial):
        # å®šä¹‰å‚æ•°æœç´¢ç©ºé—´
        params = {
            'buy_threshold': trial.suggest_float('buy_threshold', 0.1, 0.5),
            'sell_threshold': trial.suggest_float('sell_threshold', 0.5, 0.9),
            'position_size': trial.suggest_int('position_size', 10, 100),
            'stop_loss': trial.suggest_float('stop_loss', 0.02, 0.1),
            'take_profit': trial.suggest_float('take_profit', 0.05, 0.3),
            'max_positions': trial.suggest_int('max_positions', 1, 5)
        }
        
        # è¿™é‡Œåº”è¯¥è¿è¡Œå›æµ‹
        # ç®€åŒ–ç‰ˆç¤ºä¾‹
        
        # æ¨¡æ‹Ÿå›æµ‹æ”¶ç›Š
        # å®é™…åº”è¯¥è°ƒç”¨ backtest_engine
        pnl = simulate_backtest(params)
        
        return pnl
    
    def simulate_backtest(params: dict) -> float:
        """æ¨¡æ‹Ÿå›æµ‹ (å®é™…åº”è¯¥ä½¿ç”¨çœŸå®å›æµ‹)"""
        
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¨¡æ‹Ÿ
        # å®é™…åº”è¯¥è¿è¡Œå®Œæ•´çš„å›æµ‹
        
        import random
        random.seed(42)
        
        # æ¨¡æ‹Ÿæ”¶ç›Š (å®é™…åº”è¯¥ç”¨ç­–ç•¥å‚æ•°å›æµ‹)
        base_return = 0.1
        noise = random.gauss(0, 0.05)
        
        # å‚æ•°åˆç†æ€§å¥–åŠ±
        if params['buy_threshold'] < params['sell_threshold']:
            reward = 0.02
        else:
            reward = -0.02
        
        return base_return + noise + reward
    
    # åˆ›å»ºä¼˜åŒ–ç ”ç©¶
    study = optuna.create_study(
        study_name='polymarket_strategy',
        direction='maximize',
        storage='sqlite:///optimization.db'
    )
    
    print("ğŸš€ å¼€å§‹è‡ªåŠ¨ä¼˜åŒ–")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # è¿è¡Œä¼˜åŒ–
    study.optimize(objective, n_trials=100, show_progress_bar=True)
    
    # è¾“å‡ºç»“æœ
    print("\nâœ… ä¼˜åŒ–å®Œæˆ!")
    print(f"\nğŸ“Š æœ€ä½³å‚æ•°:")
    print(f"   æ”¶ç›Š: {study.best_value:.4f}")
    print(f"   å‚æ•°: {json.dumps(study.best_params, indent=2)}")
    
    # ä¿å­˜ç»“æœ
    result = {
        'timestamp': datetime.now().isoformat(),
        'best_value': study.best_value,
        'best_params': study.best_params,
        'n_trials': len(study.trials)
    }
    
    with open('optimization_results.json', 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: optimization_results.json")
    
    return study.best_params

if __name__ == "__main__":
    best_params = optimize_strategy_params()
EOF

echo "âœ… è‡ªåŠ¨ä¼˜åŒ–æ¨¡å—å·²åˆ›å»º"
echo ""

# åˆ›å»ºå›æµ‹æ¡†æ¶
echo "ğŸ“‹ æ­¥éª¤ 5: åˆ›å»ºå›æµ‹æ¡†æ¶"
echo "------------------------------"

cat > backtest_engine.py << 'EOF'
#!/usr/bin/env python3
"""
å›æµ‹å¼•æ“
ç­–ç•¥å›æµ‹å’Œè¯„ä¼°
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List

class BacktestEngine:
    """å›æµ‹å¼•æ“"""
    
    def __init__(self, initial_capital: float = 1000.0):
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.positions = {}
        self.trades = []
        self.equity_curve = []
    
    def run_backtest(self, df: pd.DataFrame, strategy_params: dict) -> dict:
        """
        è¿è¡Œå›æµ‹
        
        å‚æ•°:
            df: åŒ…å«ä»·æ ¼æ•°æ®çš„ DataFrame
            strategy_params: ç­–ç•¥å‚æ•°å­—å…¸
        """
        
        print("ğŸš€ å¼€å§‹å›æµ‹")
        print(f"   åˆå§‹èµ„é‡‘: ${self.initial_capital}")
        print(f"   æ•°æ®é•¿åº¦: {len(df)} æ¡")
        
        # å›æµ‹å¾ªç¯
        for i, row in df.iterrows():
            # è·å–ä¿¡å·
            signal = self.generate_signal(row, strategy_params)
            
            # æ‰§è¡Œäº¤æ˜“
            if signal == 1:  # ä¹°å…¥ä¿¡å·
                self.buy(row, strategy_params)
            elif signal == -1:  # å–å‡ºä¿¡å·
                self.sell(row, strategy_params)
            
            # æ›´æ–°æƒç›Š
            self.update_equity(row)
        
        # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        metrics = self.calculate_metrics()
        
        print(f"\nâœ… å›æµ‹å®Œæˆ")
        print(f"   æœ€ç»ˆèµ„é‡‘: ${self.capital:.2f}")
        print(f"   æ€»æ”¶ç›Š: {metrics['total_return']:.2%}")
        
        return metrics
    
    def generate_signal(self, row: pd.Series, params: dict) -> int:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        
        # ç®€åŒ–ç‰ˆä¿¡å·ç”Ÿæˆ
        # å®é™…åº”è¯¥ä½¿ç”¨ ML æ¨¡å‹æˆ–å¤æ‚ç­–ç•¥
        
        rsi = row.get('rsi', 50)
        price_momentum = row.get('price_momentum_24h', 0)
        
        if rsi < 30 and price_momentum > 0:
            return 1  # ä¹°å…¥
        elif rsi > 70 and price_momentum < 0:
            return -1  # å–å‡º
        
        return 0  # æŒæœ‰
    
    def buy(self, row: pd.Series, params: dict):
        """ä¹°å…¥"""
        
        if self.capital <= 0:
            return
        
        position_size = params.get('position_size', 10)
        cost = min(position_size, self.capital)
        
        self.capital -= cost
        self.positions['long'] = self.positions.get('long', 0) + cost / row['price']
        
        self.trades.append({
            'type': 'buy',
            'price': row['price'],
            'amount': cost,
            'timestamp': row.get('timestamp', datetime.now())
        })
    
    def sell(self, row: pd.Series, params: dict):
        """å–å‡º"""
        
        if 'long' not in self.positions or self.positions['long'] <= 0:
            return
        
        amount = self.positions['long']
        revenue = amount * row['price']
        
        self.capital += revenue
        self.positions['long'] = 0
        
        self.trades.append({
            'type': 'sell',
            'price': row['price'],
            'amount': revenue,
            'timestamp': row.get('timestamp', datetime.now())
        })
    
    def update_equity(self, row: pd.Series):
        """æ›´æ–°æƒç›Š"""
        
        position_value = self.positions.get('long', 0) * row['price']
        total_equity = self.capital + position_value
        
        self.equity_curve.append({
            'timestamp': row.get('timestamp'),
            'equity': total_equity
        })
    
    def calculate_metrics(self) -> dict:
        """è®¡ç®—ç»©æ•ˆæŒ‡æ ‡"""
        
        if not self.equity_curve:
            return {}
        
        equity_df = pd.DataFrame(self.equity_curve)
        
        # æ€»æ”¶ç›Š
        final_equity = equity_df['equity'].iloc[-1]
        total_return = (final_equity - self.initial_capital) / self.initial_capital
        
        # æœ€å¤§å›æ’¤
        equity_df['peak'] = equity_df['equity'].cummax()
        equity_df['drawdown'] = (equity_df['equity'] - equity_df['peak']) / equity_df['peak']
        max_drawdown = equity_df['drawdown'].min()
        
        # å¤æ™®æ¯”ç‡ (ç®€åŒ–ç‰ˆ)
        returns = equity_df['equity'].pct_change().dropna()
        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() != 0 else 0
        
        # èƒœç‡
        if self.trades:
            trades_df = pd.DataFrame(self.trades)
            buy_trades = trades_df[trades_df['type'] == 'buy']
            sell_trades = trades_df[trades_df['type'] == 'sell']
            
            if len(sell_trades) > 0:
                # ç®€åŒ–çš„èƒœç‡è®¡ç®—
                win_rate = 0.5  # å®é™…éœ€è¦è®¡ç®—æ¯ç¬”äº¤æ˜“çš„ç›ˆäº
            else:
                win_rate = 0
        else:
            win_rate = 0
        
        return {
            'total_return': total_return,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'num_trades': len(self.trades),
            'final_capital': final_equity
        }

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    import json
    from feature_engineering import FeatureEngineer
    
    # åŠ è½½æ•°æ®
    with open('historical_data/sample_history.json', 'r') as f:
        data = json.load(f)
    
    # ç‰¹å¾å·¥ç¨‹
    engineer = FeatureEngineer()
    df = engineer.process_all_features(data)
    
    # è¿è¡Œå›æµ‹
    engine = BacktestEngine(initial_capital=1000)
    
    strategy_params = {
        'position_size': 100,
        'stop_loss': 0.05,
        'take_profit': 0.1
    }
    
    metrics = engine.run_backtest(df, strategy_params)
    
    print("\nğŸ“Š å›æµ‹ç»©æ•ˆ:")
    for key, value in metrics.items():
        print(f"   {key}: {value}")
EOF

echo "âœ… å›æµ‹æ¡†æ¶å·²åˆ›å»º"
echo ""

echo "=========================================="
echo "ğŸ§  Phase 4 å‡†å¤‡å®Œæˆï¼"
echo "=========================================="
echo ""
echo "ğŸ“¦ å·²åˆ›å»ºæ¨¡å—:"
echo "   - historical_data_collector.py - å†å²æ•°æ®æ”¶é›†"
echo "   - feature_engineering.py - ç‰¹å¾å·¥ç¨‹"
echo "   - model_training.py - æ¨¡å‹è®­ç»ƒ"
echo "   - auto_optimizer.py - è‡ªåŠ¨ä¼˜åŒ–"
echo "   - backtest_engine.py - å›æµ‹å¼•æ“"
echo ""
echo "ğŸš€ å®æ–½æ­¥éª¤:"
echo ""
echo "1. å®‰è£…ä¾èµ–:"
echo "   pip install pandas numpy scikit-learn optuna joblib"
echo ""
echo "2. æ”¶é›†å†å²æ•°æ®:"
echo "   python3 historical_data_collector.py"
echo ""
echo "3. ç‰¹å¾å·¥ç¨‹:"
echo "   python3 feature_engineering.py"
echo ""
echo "4. è®­ç»ƒæ¨¡å‹:"
echo "   python3 model_training.py"
echo ""
echo "5. è‡ªåŠ¨ä¼˜åŒ–:"
echo "   python3 auto_optimizer.py"
echo ""
echo "6. å›æµ‹éªŒè¯:"
echo "   python3 backtest_engine.py"
echo ""
echo "ğŸ¯ ç›®æ ‡: æ¨¡å‹å‡†ç¡®ç‡ >65%, æœˆæ”¶ç›Šç‡ >10%"
echo "=========================================="
